{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fxZkTppSGk0q"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "import csv\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRhVhOLvHE6H",
    "outputId": "52d74172-a18d-4920-c2cc-de8c56aabc6f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JA5bvbsyHaww"
   },
   "outputs": [],
   "source": [
    "home = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "skFiknEKGk0-"
   },
   "outputs": [],
   "source": [
    "# Loading a text file into memory\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# Loading a binary file into memory\n",
    "def load_doc_bin(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    text = load(file)\n",
    "    file.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping image with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Ro9VrB5LGk1C"
   },
   "outputs": [],
   "source": [
    "# Mapping image with descriptions\n",
    "def all_img_captions(filename):\n",
    "    file = load_doc(filename)\n",
    "    captions = file.split('\\n')\n",
    "\n",
    "    descriptions ={}\n",
    "    for caption in captions[1:]:\n",
    "        cap=caption.split(\":\")\n",
    "        img = cap[0].strip()\n",
    "        caption_ = cap[1].strip()\n",
    "        \n",
    "        if img not in descriptions:\n",
    "            descriptions[img] = [caption_]\n",
    "        else:\n",
    "            descriptions[img].append(caption_)\n",
    "    # print(descriptions)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text in captions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zVTorB5bGk1G"
   },
   "outputs": [],
   "source": [
    "#Changing to lower cases, removing punctuations and stop words and also numbers\n",
    "def cleaning_text(captions):\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    for img,caps in captions.items():\n",
    "        for i,img_caption in enumerate(caps):\n",
    "\n",
    "            img_caption.replace(\"-\",\" \")\n",
    "            desc = img_caption.split()\n",
    "\n",
    "            #convert to lower case\n",
    "            desc = [word.lower() for word in desc]\n",
    "            #remove punctuation\n",
    "            desc = [word.translate(table) for word in desc]\n",
    "            #remove 's and a \n",
    "            desc = [word for word in desc if(len(word)>1)]\n",
    "            #remove tokens with numbers\n",
    "            desc = [word for word in desc if(word.isalpha())]\n",
    "\n",
    "            img_caption = ' '.join(desc)\n",
    "            captions[img][i]= img_caption\n",
    "            \n",
    "    # print(list(captions.values())[0])\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vocabulary from descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6YQmr2oDGk1J"
   },
   "outputs": [],
   "source": [
    "def text_vocabulary(descriptions):\n",
    "    vocab = set()\n",
    "    \n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "    \n",
    "    # print(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving cleaned description to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "-Cfj1xs2Gk1N"
   },
   "outputs": [],
   "source": [
    "#All descriptions in one file \n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + ' ' + desc )\n",
    "    data = \"\\n\".join(lines)\n",
    "    file = open(filename,\"w\")\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxYlxcICGk1T",
    "outputId": "21572420-df7a-4943-b422-efb3a881b513",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of descriptions = 8091\n",
      "Length of vocabulary =  8762\n"
     ]
    }
   ],
   "source": [
    "filename = home + \"captions_8k.txt\"\n",
    "\n",
    "descriptions = all_img_captions(filename)\n",
    "# print(description)/\n",
    "print(\"Length of descriptions =\" ,len(descriptions))\n",
    "\n",
    "clean_descriptions = cleaning_text(descriptions)\n",
    "\n",
    "vocabulary = text_vocabulary(clean_descriptions)\n",
    "print(\"Length of vocabulary = \", len(vocabulary))\n",
    "\n",
    "save_descriptions(clean_descriptions, home + \"descriptions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oGbMcuxhGk1Y",
    "outputId": "370e9b19-4536-4f54-8621-6b949f7c8bcb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet = ResNet101(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "# resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features of image using RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "H2B34cVIGk1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features(directory):\n",
    "        features = {}\n",
    "        img_dir = glob(directory + '\\*.jpg')\n",
    "        # print(len(img_dir))\n",
    "        for image in img_dir:\n",
    "            filename = image\n",
    "            \n",
    "            image = Image.open(filename)\n",
    "            image = image.resize((224,224))\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            # print(image.shape)\n",
    "\n",
    "            filename = filename.split('\\\\')[1]\n",
    "            \n",
    "            # print(image.shape)\n",
    "            feature = resnet.predict(image)\n",
    "            # print(feature.shape)\n",
    "            features[filename] = feature\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZJC6l7EcGk1e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features = extract_features('./train_dir')\n",
    "# dump(features, open( home + \"image_features.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yTPX6lfGGk1g",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# features = load(open(\"features_10k.p\",\"rb\"))\n",
    "# len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading everything into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "kb9R-pDIGk1j"
   },
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename):    \n",
    "    #loading clean_descriptions \n",
    "    file = load_doc(filename) \n",
    "    descriptions = {} \n",
    "    for line in file.split(\"\\n\"):         \n",
    "        words = line.split() \n",
    "        if len(words)<1 : \n",
    "            continue      \n",
    "        image, image_caption = words[0], words[1:]          \n",
    "        if image not in train_features.keys(): \n",
    "            continue  \n",
    "        if image not in descriptions: \n",
    "            descriptions[image] = [] \n",
    "        desc = '<start> ' + \" \".join(image_caption) + ' <end>' \n",
    "        descriptions[image].append(desc) \n",
    "    return descriptions \n",
    " \n",
    "def load_features(): \n",
    "    #loading all features \n",
    "    all_features = load_doc_bin(home + \"train_8K_6500.p\")\n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "PrU2BMSyGk1l",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    }
   ],
   "source": [
    "train_features = load_features() \n",
    "features = train_features \n",
    "train_descriptions = load_clean_descriptions(home + \"descriptions.txt\") \n",
    "\n",
    "print(len(features)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer to convert characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "z6QaqNT6Gk1m"
   },
   "outputs": [],
   "source": [
    "#converting dictionary to list of descriptions\n",
    "def dict_to_list(descriptions):\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1DVghxSGk1n",
    "outputId": "64a9f1ce-39f8-43c0-e6c8-18505e9d073a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "# print(tokenizer.word_index)\n",
    "\n",
    "with open(home + 'tokenizer.p', 'wb') as token_file:\n",
    "    dump(tokenizer, token_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jrr1M3RJGk1o",
    "outputId": "b7b34251-64a1-4627-cc21-11b25131725e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7945"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = load_doc_bin(home + 'tokenizer.p')\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Max length of descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHCagkN3Gk1p",
    "outputId": "46b1688c-52af-40d0-f09f-d1b30e3b76aa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_length_func(descriptions):\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    max_ = 0\n",
    "    for d in desc_list:\n",
    "        if len(d.split()) > max_:\n",
    "            max_ = len(d.split())\n",
    "            # print(max_, d)\n",
    "    return max_\n",
    "\n",
    "max_length = max_length_func(descriptions)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN_10hpaGk1r"
   },
   "source": [
    "#### Generator for training in-memory and preparing inputs for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLBPI1Myvl50",
    "outputId": "53b59a64-2fd7-40be-8cb0-d61d1438612e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 2048), (32, 32), (32, 7945))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(descriptions, features, tokenizer, max_length):\n",
    "    while 1:\n",
    "        for key, description_list in descriptions.items():\n",
    "            if key not in features.keys():\n",
    "              continue\n",
    "\n",
    "            feature = features[key][0]\n",
    "            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
    "            yield [[input_image, input_sequence], output_word]\n",
    "\n",
    "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "\n",
    "    for desc in desc_list:\n",
    "        # encoding the sequence\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        # split one sequence into multiple X,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "            X1.append(feature)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "\n",
    "[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n",
    "a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet and LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "0uKeDKA2vyA5"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    \n",
    "    # features from the CNN model\n",
    "    cnn_input = Input(shape=(2048,))\n",
    "    layer = Dropout(0.5)(cnn_input)\n",
    "    cnn_input = Dense(256, activation='relu')(layer)\n",
    "\n",
    "    # LSTM sequence model\n",
    "    lstm_input = Input(shape=(max_length,))\n",
    "    layer = Embedding(vocab_size, 256, mask_zero=True)(lstm_input)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    lstm_input = LSTM(256)(layer)\n",
    "\n",
    "    # Merging both models\n",
    "    merged_model = add([cnn_input, lstm_input])\n",
    "    merged_model = Dense(256, activation='relu')(merged_model)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(merged_model)\n",
    "    \n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    # summary of the model\n",
    "    # print(model.summary())\n",
    "    plot_model(model, to_file= home + 'model.png', show_shapes=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfwdPnv3v8I7",
    "outputId": "f2f2eaff-82f3-426d-aacd-3b41ce088e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: train= 6500\n",
      "Photos: train= 6500\n",
      "Vocabulary Size: 7945\n",
      "Description Length:  32\n"
     ]
    }
   ],
   "source": [
    "print('Descriptions: train=', len(train_descriptions))\n",
    "print('Photos: train=', len(train_features))\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Description Length: ', max_length)\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "#Loading the saved model\n",
    "model = keras.models.load_model(\"./model_20.h5\")\n",
    "\n",
    "# epochs = 20\n",
    "# steps = len(train_descriptions)\n",
    "# # # os.mkdir(home+\"models test\")\n",
    "# for i in range(12, epochs):\n",
    "#     generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "#     model.fit(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n",
    "#     model.save(home+\"models test1/model_\" + str(i) + \".h5\")\n",
    "#     print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "59Wz6rs0AaHX"
   },
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    " for word, index in tokenizer.word_index.items():\n",
    "     if index == integer:\n",
    "         return word\n",
    " return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "OarAoLB--fEj"
   },
   "outputs": [],
   "source": [
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'start'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        pred = model.predict([photo,sequence], verbose=0)\n",
    "        pred = np.argmax(pred)\n",
    "        word = word_for_id(pred, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'end':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9fGs1262-gl2"
   },
   "outputs": [],
   "source": [
    "def generate_feature(filename):\n",
    "    image = Image.open(filename)\n",
    "    image = image.resize((224,224))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return resnet.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating captions for all images and storing in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "MW6pgzS--ilp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(home+\"predicted.csv\", 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['Image','Caption Generated'])\n",
    "\n",
    "test_dir=glob(home+'mod_testdata/*.jpg')\n",
    "# print(test_dir)\n",
    "for image in test_dir:\n",
    "  description = generate_desc(model, tokenizer, generate_feature(image), max_length)\n",
    "  writer.writerow([image,description])\n",
    "f.close()\n",
    "# print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnumWFWFjII3",
    "outputId": "d6a14be6-3b46-4e0d-b490-1ff3ef399198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dog is running through the grass end\n"
     ]
    }
   ],
   "source": [
    "filename = \"./mod_testdata/3082934678_58534e9d2c.jpg\"\n",
    "description = generate_desc(model, tokenizer, generate_feature(filename), max_length)\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "id": "b3wNdhwpCd-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\436pr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\users\\436pr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\users\\436pr\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1346051107_9cdc14e070.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(1)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(2)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m filename:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m hypothesis \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(predict_dict[filename])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# print(hypothesis,descriptions[img.split('/')[5]])\u001b[39;00m\n\u001b[0;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m descriptions[img\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]]\n",
      "\u001b[1;31mKeyError\u001b[0m: '1346051107_9cdc14e070.jpg'"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "BLEUscore=[]\n",
    "score=[]\n",
    "data=pd.read_csv(home+\"predicted.csv\")\n",
    "predicted=[]\n",
    "predict_dict={}\n",
    "\n",
    "with open(home+'predicted.csv') as file:\n",
    "    content = file.readlines()\n",
    "print(content[3], len(content))\n",
    "for x in content[2::2]:\n",
    "    y=x.split(',')\n",
    "    \n",
    "    predict_dict[y[0].split('\\\\')[1]]=y[1].split()\n",
    "# print(predict_dict)\n",
    "\n",
    "img_dir=glob(home+'mod_testdata/*.jpg')\n",
    "bleu = 0\n",
    "for img in img_dir:\n",
    "    filename=img.split('\\\\')[1]    \n",
    "    \n",
    "    if '(1)' in filename or '(2)' in filename:\n",
    "        continue\n",
    "\n",
    "    hypothesis = predict_dict[filename][1:len(predict_dict[filename])-1]\n",
    "    # print(hypothesis,descriptions[img.split('/')[5]])\n",
    "    x = descriptions[img.split('\\\\')[1]]\n",
    "\n",
    "    act = list()\n",
    "    for string in x:\n",
    "        act.append(string.split())\n",
    "\n",
    "    bleu += sentence_bleu(act, hypothesis)\n",
    "    \n",
    "# BLEUscore.append(score)\n",
    "print(\"BLUE SCORE:\",bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Meteor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMR4CqXeJrKK",
    "outputId": "dbfdecd0-1604-42b0-e601-4b90018eefdc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZueLAGFYwutv",
    "outputId": "ffadad98-9987-4911-bd01-ebb71ec3cf43"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate import meteor\n",
    "\n",
    "meteor=0\n",
    "for img in img_dir:\n",
    "    filename=img.split('\\\\')[1]\n",
    "    if '(1)' in filename or '(2)' in filename:\n",
    "        continue\n",
    "    hypothesis = predict_dict[filename][1:len(predict_dict[filename])-1]\n",
    "    x = descriptions[img.split('\\\\')[1]]\n",
    "\n",
    "    act = list()\n",
    "    for string in x:\n",
    "        act.append(string.split())\n",
    "\n",
    "    meteor += meteor_score(act, hypothesis)\n",
    "    \n",
    "print(\"Meteor SCORE:\",meteor/1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3o2R6t6O2CD",
    "outputId": "4c36b73f-7336-40ba-8645-000933adb553",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate import meteor\n",
    "\n",
    "BLEUscore=[]\n",
    "score=[]\n",
    "data=pd.read_csv(home+\"predicted.csv\")\n",
    "predicted=[]\n",
    "predict_dict={}\n",
    "\n",
    "with open(home+'predicted.csv') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "for x in content[2::2]:\n",
    "    y=x.split(',')\n",
    "    predict_dict[y[0].split('\\\\')[1]]=y[1]\n",
    "\n",
    "img_dir=glob(home+'mod_testdata/*.jpg')\n",
    "rouge= Rouge()\n",
    "meteor=0\n",
    "rouge_1={'r':0.0,'f':0.0,'p':0.0}\n",
    "rouge_2={'r':0.0,'f':0.0,'p':0.0}\n",
    "rouge_l={'r':0.0,'f':0.0,'p':0.0}\n",
    "r1=r2=r3=0\n",
    "p1=p2=p3=0\n",
    "f1=f2=f3=0\n",
    "\n",
    "for img in img_dir:    \n",
    "    filename=img.split('\\\\')[1]\n",
    "    if '(1)' in filename or '(2)' in filename:\n",
    "    continue\n",
    "    \n",
    "    hypothesis = predict_dict[filename][:len(predict_dict[filename])-1]\n",
    "    # print(hypothesis,descriptions[img.split('/')[5]])\n",
    "    x = descriptions[img.split('\\\\')[1]]\n",
    "    #   print(x)\n",
    "    #   print(hypothesis)\n",
    "    act = list()\n",
    "    act.append(hypothesis)\n",
    "    for string in hypothesis:\n",
    "        act.append(string.split())\n",
    " \n",
    "  if len(x)==5:\n",
    "      for i in range(5):\n",
    "          r1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['r']\n",
    "          p1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['p']\n",
    "          f1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['f']\n",
    "          r2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['r']\n",
    "          p2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['p']\n",
    "          f2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['f']\n",
    "          r3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['r']\n",
    "          p3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['p']\n",
    "          f3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['f']\n",
    "  else:\n",
    "      for i in range(4):\n",
    "          r1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['r']\n",
    "          p1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['p']\n",
    "          f1 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-1']['f']\n",
    "          r2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['r']\n",
    "          p2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['p']\n",
    "          f2 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-2']['f']\n",
    "          r3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['r']\n",
    "          p3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['p']\n",
    "          f3 +=rouge.get_scores(hypothesis, x[i])[0]['rouge-l']['f']\n",
    "\n",
    "print(r1/2000,p1/2000,f1/2000)\n",
    "print(r2/2000,p2/2000,f2/2000)\n",
    "print(r3/2000,p3/2000,f3/2000)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksy6q3pOnP-J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kavithavin kavalan prathap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
